{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gyro Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터 수집"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습에 사용할 데이터를 수집합니다. 수집하고자 하는 데이터의 이름을 설정하고 gathering_motion 메서드를 통해 데이터를 수집합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-1. gathering_data 모듈과 Pymodi 패키지를 import합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gathering_data import DataGathering\n",
    "import modi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-2. 모디 객체와 DataGathering 클래스 객체를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle = modi.MODI(3)\n",
    "gyro = bundle.gyros[0]\n",
    "btn = bundle.buttons[0]\n",
    "\n",
    "dg = DataGathering()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-3. 파일 이름을 입력하고, gathering_motion 메서드를 실행하여 데이터를 수집합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'new' # 파일은 /data/new.csv 로 저장됩니다.\n",
    "dg.gathering_motion(btn, gyro, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수집한 데이터를 통해 학습 모델을 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-1. gesture_detection 모듈을 import 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PyMODI (v0.9.0)\n"
     ]
    }
   ],
   "source": [
    "from gesture_detection import DetectGesture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-2. DetectGesture 클래스 객체를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = DetectGesture()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-3. 모델 이름을 입력하고 training_model 메서드를 통해 학습 및 모델을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version = 2.0.0\n",
      "\n",
      "Processing index 0 for gesture 'back'.\n",
      "      Unnamed: 0     aX     aY     aZ     gX     gY    gZ    roll  pitch  \\\n",
      "0              0   0.00   0.00   0.00   0.00   0.00  0.00    0.00   0.00   \n",
      "1              1  -0.34  36.83 -25.35 -26.15   0.00  0.00    0.00   0.00   \n",
      "2              2  -0.34  36.83 -25.35 -26.15 -14.70  5.12  120.76   4.03   \n",
      "3              3   4.22  36.83 -25.35 -26.15 -14.70  5.12  120.76   4.03   \n",
      "4              4   4.22  41.74  -9.03  18.12 -14.70  5.12  120.76   4.03   \n",
      "...          ...    ...    ...    ...    ...    ...   ...     ...    ...   \n",
      "1245          20  12.44  42.21 -14.11  -1.70   3.34  0.69  108.16  44.78   \n",
      "1246          21  13.72  42.21 -14.11  -1.70   3.34  0.69  108.16  44.78   \n",
      "1247          22  13.72  36.33 -27.43   5.15   3.47  0.69  108.16  44.78   \n",
      "1248          23  13.72  36.33 -27.43   5.15   3.47  4.11  127.19  28.70   \n",
      "1249          24  14.54  36.33 -27.43   5.15   3.47  4.11  127.19  28.70   \n",
      "\n",
      "        yaw    vi  \n",
      "0      0.00  0.00  \n",
      "1      0.00  0.00  \n",
      "2      0.00  0.00  \n",
      "3     43.22 -2.29  \n",
      "4     43.22 -2.29  \n",
      "...     ...   ...  \n",
      "1245  46.02  0.89  \n",
      "1246  46.10  0.13  \n",
      "1247  46.10  0.13  \n",
      "1248  46.10  0.13  \n",
      "1249  46.59  0.04  \n",
      "\n",
      "[1250 rows x 11 columns]\n",
      "(1250, 11)\n",
      "\tThere are 50 recordings of the back gesture.\n",
      "Processing index 1 for gesture 'go'.\n",
      "      Unnamed: 0    aX     aY     aZ     gX     gY    gZ  roll  pitch     yaw  \\\n",
      "0              0  0.00   0.00   0.00   0.00   0.00  0.00  0.00   0.00    0.00   \n",
      "1              1  2.38  -2.50  51.45   0.00   0.00  0.00  0.00   0.00    0.00   \n",
      "2              2  2.38  -2.50  51.45   3.41   0.55 -1.14 -2.58   2.05    0.00   \n",
      "3              3 -1.93  -2.50  51.45   3.41   0.55 -1.14 -2.58   2.05   14.02   \n",
      "4              4 -1.93  -1.91  50.47   3.99  -1.19 -1.14 -2.58   2.05   14.02   \n",
      "...          ...   ...    ...    ...    ...    ...   ...   ...    ...     ...   \n",
      "1220          20 -1.99  -5.00  48.82   3.40   5.40  1.28 -5.91  -4.96 -169.09   \n",
      "1221          21 -5.15  -5.00  48.82   3.40   5.40  0.99 -5.91  -2.07 -169.09   \n",
      "1222          22 -5.15 -18.01  77.35   3.40   5.40  0.99 -5.91  -2.07 -169.09   \n",
      "1223          23 -5.15 -18.01  77.35  18.15  19.39  0.99 -9.22  -4.18 -169.09   \n",
      "1224          24 -8.69 -18.01  77.35  18.15  19.39  5.52 -9.22  -4.18 -169.09   \n",
      "\n",
      "        vi  \n",
      "0     0.00  \n",
      "1     0.00  \n",
      "2     0.00  \n",
      "3    -0.53  \n",
      "4    -0.53  \n",
      "...    ...  \n",
      "1220 -0.28  \n",
      "1221 -0.00  \n",
      "1222 -0.00  \n",
      "1223 -0.00  \n",
      "1224 -4.49  \n",
      "\n",
      "[1225 rows x 11 columns]\n",
      "(1225, 11)\n",
      "\tThere are 49 recordings of the go gesture.\n",
      "Processing index 2 for gesture 'left'.\n",
      "      Unnamed: 0     aX     aY     aZ    gX    gY    gZ   roll  pitch     yaw  \\\n",
      "0              0   0.00   0.00   0.00  0.00  0.00  0.00   0.00   0.00    0.00   \n",
      "1              1  18.66   8.99  44.17 -0.64  0.00  0.00   0.00   0.00    0.00   \n",
      "2              2  18.66   8.99  44.17 -0.64  8.51 -2.69  12.40  23.12    0.00   \n",
      "3              3  17.07   8.99  44.17 -0.64  8.51 -2.69  12.40  23.12 -165.13   \n",
      "4              4  17.07  10.00  43.54  0.75  5.39 -2.69  12.40  23.12 -165.13   \n",
      "...          ...    ...    ...    ...   ...   ...   ...    ...    ...     ...   \n",
      "1220          20   2.84   9.51  49.42  1.82  2.13 -1.25  10.71   2.30 -149.22   \n",
      "1221          21   2.84   9.51  49.42  1.82  2.13  1.48  11.11   3.28 -149.17   \n",
      "1222          22  15.46   4.09  51.33  1.82  2.13  1.48  11.11   3.28 -149.17   \n",
      "1223          23  15.46   4.09  51.33  2.05  4.61 -0.02   5.97   3.28 -149.17   \n",
      "1224          24  15.46   4.09  51.33  2.05  4.61 -0.02   5.97  18.03 -149.03   \n",
      "\n",
      "        vi  \n",
      "0     0.00  \n",
      "1     0.00  \n",
      "2     0.00  \n",
      "3     0.06  \n",
      "4     0.06  \n",
      "...    ...  \n",
      "1220  0.25  \n",
      "1221  0.25  \n",
      "1222  0.02  \n",
      "1223  0.02  \n",
      "1224  2.70  \n",
      "\n",
      "[1225 rows x 11 columns]\n",
      "(1225, 11)\n",
      "\tThere are 49 recordings of the left gesture.\n",
      "Processing index 3 for gesture 'right'.\n",
      "      Unnamed: 0     aX     aY     aZ    gX    gY    gZ   roll  pitch     yaw  \\\n",
      "0              0   0.00   0.00   0.00  0.00  0.00  0.00   0.00   0.00    0.00   \n",
      "1              1   4.51   2.87  47.33  0.00  0.00  0.00   0.00   0.00    0.00   \n",
      "2              2   4.51   2.87  47.33 -1.84  1.86  1.40   3.65   3.90    0.00   \n",
      "3              3   0.51   2.87  47.33 -1.84  1.86  1.40   3.65   3.90   52.54   \n",
      "4              4   0.51   3.09  44.21 -1.79  1.86  1.40   3.65   3.90   52.54   \n",
      "...          ...    ...    ...    ...   ...   ...   ...    ...    ...     ...   \n",
      "1220          20 -11.81  -7.29  45.01 -1.11  3.15  6.90  -9.45 -13.61 -159.47   \n",
      "1221          21 -11.81  -7.29  45.01 -1.11  3.15  6.90  -9.45 -15.36 -158.65   \n",
      "1222          22 -31.48 -13.95  61.38 -0.82  3.15  6.90  -9.45 -15.36 -158.65   \n",
      "1223          23 -31.48 -13.95  61.38 -0.82  0.93  5.47 -13.01 -38.99 -158.65   \n",
      "1224          24 -99.99 -13.95  61.38 -0.82  0.93  5.47 -13.01 -38.99 -157.37   \n",
      "\n",
      "         vi  \n",
      "0      0.00  \n",
      "1      0.00  \n",
      "2      0.00  \n",
      "3     -0.36  \n",
      "4     -0.36  \n",
      "...     ...  \n",
      "1220  -0.25  \n",
      "1221  -1.75  \n",
      "1222  -1.75  \n",
      "1223  -1.75  \n",
      "1224 -23.61  \n",
      "\n",
      "[1225 rows x 11 columns]\n",
      "(1225, 11)\n",
      "\tThere are 49 recordings of the right gesture.\n",
      "Data set parsing and preparation complete.\n",
      "inputs :  4925\n",
      "TRAIN_SPLIT :  2955\n",
      "TEST_SPLIT :  3940\n",
      "[0.20261187 0.92061621 0.63424181 1.         0.73563218 0.42350529\n",
      " 0.88311335 0.38198103 0.45082562 0.20261187 0.92061621 0.63424181\n",
      " 1.         0.73563218 0.42350529 0.79425772 0.56656129 0.44309941\n",
      " 0.26080277 0.90478997 0.68744564 1.         0.73563218 0.42350529\n",
      " 0.79425772 0.56656129 0.44309941 0.26080277 0.90478997 0.68744564\n",
      " 0.7593617  0.68798665 0.62475758 0.77139747 0.56656129 0.44309941\n",
      " 0.26080277 0.90478997 0.68744564 0.7593617  0.68798665 0.62475758\n",
      " 0.77139747 0.31401475 0.4431273  0.20722105 0.88862699 0.72281821\n",
      " 0.7593617  0.68798665 0.62475758 0.77139747 0.31401475 0.4431273\n",
      " 0.20722105 0.88862699 0.72281821 0.32659574 0.51928068 0.54208456\n",
      " 0.72962308 0.31401475 0.4431273  0.20722105 0.88862699 0.72281821\n",
      " 0.32659574 0.51928068 0.54208456 0.72962308 0.37074113 0.44268102\n",
      " 0.21144613 0.90150686 0.6804871  0.2812766  0.51928068 0.54208456\n",
      " 0.72962308 0.37074113 0.44268102 0.21144613 0.90150686 0.6804871\n",
      " 0.2812766  0.63644791 0.47282097 0.76282487 0.41938883 0.44268102\n",
      " 0.22220088 0.90150686 0.6804871  0.2812766  0.63644791 0.47282097\n",
      " 0.76282487 0.41938883 0.43704675 0.22220088 0.88231333 0.68063207\n",
      " 0.34680851 0.6114201  0.47282097 0.76282487 0.41938883 0.43704675\n",
      " 0.22220088 0.88231333 0.68063207 0.34680851 0.6114201  0.5356569\n",
      " 0.7300313  0.37688795 0.43422961 0.19310543 0.88231333 0.68063207\n",
      " 0.34680851 0.6114201  0.5356569  0.7300313  0.37688795 0.43422961\n",
      " 0.19310543 0.8951932  0.67802262 0.4193617  0.58027438 0.5356569\n",
      " 0.7300313  0.37688795 0.43422961 0.19310543 0.8951932  0.67802262\n",
      " 0.4193617  0.58027438 0.50590126 0.73479385 0.40990516 0.43043624\n",
      " 0.19915498 0.87894604 0.67802262 0.4193617  0.58027438 0.50590126\n",
      " 0.73479385 0.40990516 0.43043624 0.19915498 0.87894604 0.68498115\n",
      " 0.39829787 0.57545421 0.54513215 0.73479385 0.40990516 0.43043624\n",
      " 0.19915498 0.87894604 0.68498115 0.39829787 0.57545421 0.54513215\n",
      " 0.7113893  0.37899543 0.42904162 0.21355867 0.87423184 0.68585097\n",
      " 0.39829787 0.57545421 0.54513215 0.7113893  0.37899543 0.42904162\n",
      " 0.21355867 0.87423184 0.68585097 0.31744681 0.58898776 0.56408267\n",
      " 0.7113893  0.37899543 0.42904162 0.21355867 0.87423184 0.68585097\n",
      " 0.31744681 0.58898776 0.56408267 0.70621853 0.38918159 0.42906951\n",
      " 0.19339351 0.88711171 0.69063497 0.28744681 0.58898776 0.56408267\n",
      " 0.70621853 0.38918159 0.42906951 0.19339351 0.88711171 0.69063497\n",
      " 0.28744681 0.61364479 0.55111653 0.72281943 0.38338602 0.42906951\n",
      " 0.24159785 0.88711171 0.69063497 0.28744681 0.61364479 0.55111653\n",
      " 0.72281943 0.38338602 0.42957157] [0. 0. 1. 0.]\n",
      "Data set randomization and splitting complete.\n",
      "inputs_train:  2955\n",
      "inputs_train_shape:  (2955, 225)\n",
      "inputs_test:  985\n",
      "inputs_validate:  985\n",
      "Train on 2955 samples\n",
      "Epoch 1/5\n",
      "2285/2955 [======================>.......] - ETA: 1s - loss: 0.2546 - acc: 0.9081"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-168aab963f6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Repos/ai-contents-gyro-car/src/gesture_detection.py\u001b[0m in \u001b[0;36mtraining_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m#history = model.fit(inputs_train, outputs_train, epochs=5, batch_size=1, validation_data=(inputs_validate, outputs_validate)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;31m#model.save('../model/model_car_acc_1.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dg.training_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 학습된 모델을 활용하여 콘텐츠 제작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 생성된 모델을 활용하여 콘텐츠를 제작합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-1. gesture_detection 모듈과 Pymodi 및 필수 패키지들을 import 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gesture_detection import DetectGesture\n",
    "from IPython.display import clear_output\n",
    "import modi\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-2. 모디 객체와 DetectGesture 클래스 객체를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle = modi.MODI()\n",
    "gyro = bundle.gyros[0]\n",
    "btn = bundle.buttons[0]\n",
    "mot = bundle.motors[0]\n",
    "dg = DetectGesture()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-3. 반복문 안에 있는 사용자 코드 영역을 수정하여 모터 모듈이 움직이도록 코드를 움직이도록 코드를 작성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "        time.sleep(0.1)\n",
    "        print(\"버튼을 더블클릭하면 출발합니다\")\n",
    "        clear_output(wait=True)\n",
    "        if btn.double_clicked:\n",
    "            print(\"출발!\")\n",
    "            mot.speed = 25, -25\n",
    "            time.sleep(0.1)\n",
    "            while True:\n",
    "                print(\"버튼을 눌러 데이터를 수집해보세요. 멈추려면 버튼을 더블클릭하세요.\", end='\\r')\n",
    "                if btn.clicked:\n",
    "                    pred = dg.predict(gyro, btn) #pred 변수에, 예측값을 받아와 저장합니다.\n",
    "                    time.sleep(0.1)\n",
    "                    # 사용자 코드 영역\n",
    "                    # =======================================================\n",
    "                    if pred == 'back':\n",
    "                        mot.speed = -23,23\n",
    "                        time.sleep(0.1)\n",
    "                        print('car : back!')\n",
    "                    elif pred == 'go':\n",
    "                        mot.speed = 23, -23\n",
    "                        time.sleep(0.1)\n",
    "                        print('car : go!')\n",
    "                    elif pred == 'left':\n",
    "                        mot.speed = 23, 23\n",
    "                        time.sleep(0.1)\n",
    "                        print('car : left!')\n",
    "                    elif pred == 'right':\n",
    "                        mot.speed = -23, -23\n",
    "                        time.sleep(0.1)\n",
    "                        print('car : right!')\n",
    "                    #=======================================================\n",
    "\n",
    "                time.sleep(0.1)\n",
    "                if btn.double_clicked:\n",
    "                    print(\"stop!\")\n",
    "                    mot.speed = 0, 0\n",
    "                    time.sleep(0.1)\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
